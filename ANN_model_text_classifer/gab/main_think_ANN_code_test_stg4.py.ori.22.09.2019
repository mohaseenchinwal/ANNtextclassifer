import numpy as np
import time


import nltk
from nltk.stem.lancaster import LancasterStemmer
import os
import json
import datetime
stemmer = LancasterStemmer()



# probability threshold
ERROR_THRESHOLD = 0.2
# load our calculated synapse values
synapse_file = 'synapses.json'
with open(synapse_file) as data_file:
    synapse = json.load(data_file)
    synapse_0 = np.asarray(synapse['synapse0'])
    synapse_1 = np.asarray(synapse['synapse1'])



def classify(sentence, show_details=True):
    results = think(sentence, show_details)

    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD ]
    results.sort(key=lambda x: x[1], reverse=True)
    return_results =[[classes[r[0]],r[1]] for r in results]
    print ("\n classification: %s" % ( return_results))
    return return_results

import pandas as pd

#data=pd.read_csv('Classificationtable.csv')
data=pd.read_csv('Classificationtable_1.csv', delimiter=',', names = ['Id (primary)', 'url_id', 'url', 'tokenized_source', 'Class_1', 'Class_2', 'Total_matches', 'Category'])
data = data[pd.notnull(data['tokenized_source'])]
data=data[data.Category != 'None']
#data.shape

for index,row in data.iterrows():
    x1=classify(row["tokenized_source"])
    print(row["url"],x1)

